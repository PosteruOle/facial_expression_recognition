{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d9a58fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30d9e00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that traverse through given directory and for every directory returns \n",
    "# lists of image and the corresponding emotion\n",
    "\n",
    "def load_data(data_path):\n",
    "\n",
    "    data_dir_list = os.listdir(data_path)\n",
    "\n",
    "    img_data_list = []\n",
    "    img_label_list = []\n",
    "\n",
    "    # Traverse through each folder\n",
    "    for dataset in data_dir_list:\n",
    "        if os.path.isdir(data_path + '/' +  dataset):\n",
    "            img_list=os.listdir(data_path+'/'+ dataset)\n",
    "            \n",
    "            # Resize each image\n",
    "            for img in img_list:\n",
    "                input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "\n",
    "                # Convert image to grayscale\n",
    "                input_img_gray = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                input_img_resize=cv2.resize(input_img_gray,(48,48))\n",
    "                img_data_list.append(input_img_resize)\n",
    "                img_label_list.append(dataset)\n",
    "                \n",
    "    img_data = np.array(img_data_list)\n",
    "    img_labels = np.array(img_label_list)\n",
    "\n",
    "    return img_data, img_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac847d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values to the range [0, 1]\n",
    "\n",
    "def normalize_data(data):\n",
    "\n",
    "    return data.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebae99ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because faces should be symetrical, but they aren't perfectly symetric, one possible way to make more data is\n",
    "# to add mirrored images of faces. In this way, we are doubling instances of classes. We can exclude some classes\n",
    "# from being processed this way \n",
    "    \n",
    "def add_mirror_images(images, labels, exclude = []):\n",
    "    \n",
    "    all_images_list = []\n",
    "    all_labels_list = []\n",
    "    n = len(images)\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        all_images_list.append(images[i])\n",
    "        all_labels_list.append(labels[i])\n",
    "        \n",
    "        # Don't perform mirroring if label is set to excluded\n",
    "        if labels[i] not in exclude:\n",
    "            # Mirror the image horizontally\n",
    "            mirrored_image = cv2.flip(images[i], 1)\n",
    "            all_images_list.append(mirrored_image)\n",
    "            all_labels_list.append(labels[i]) \n",
    "        \n",
    "    all_images = np.array(all_images_list)\n",
    "    all_labels = np.array(all_labels_list)\n",
    "    \n",
    "    return all_images, all_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7456bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function generates new instances of given classes up to given number of instances\n",
    "\n",
    "def add_mirrored_images_upto(images, labels, upto = 0, include = []):\n",
    "    \n",
    "    emotions = [emotion for emotion in set(labels)]\n",
    "    counts = {}\n",
    "    \n",
    "    for emotion in emotions:\n",
    "        counts[emotion] = 0\n",
    "        \n",
    "    for emotion in labels:\n",
    "        counts[emotion] += 1\n",
    "        \n",
    "    all_images_list = []\n",
    "    all_labels_list = []\n",
    "    \n",
    "    n = len(images)\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        all_images_list.append(images[i])\n",
    "        all_labels_list.append(labels[i])\n",
    "        \n",
    "        emotion = labels[i]\n",
    "        if (emotion in include) and counts[emotion] < upto:\n",
    "            # Mirror the image horizontally\n",
    "            mirrored_image = cv2.flip(images[i], 1)\n",
    "            all_images_list.append(mirrored_image)\n",
    "            all_labels_list.append(labels[i]) \n",
    "            counts[emotion] += 1\n",
    "            \n",
    "    all_images = np.array(all_images_list)\n",
    "    all_labels = np.array(all_labels_list)\n",
    "    \n",
    "    return all_images, all_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5960539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'image' is your 48x48 image with values between 0 and 1\n",
    "\n",
    "def plot_image(image, label):\n",
    "    plt.imshow(image, cmap='gray') \n",
    "    plt.axis('off')  \n",
    "    plt.show()\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3a97bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for making Bar plot which shows count of every emotion in alphabetical order\n",
    "\n",
    "def plot_count(images, labels):\n",
    "    \n",
    "    labels_set = set(labels)\n",
    "    label_counts = {}\n",
    "    \n",
    "    for label in labels_set:\n",
    "        label_counts[label] = 0\n",
    "    \n",
    "    for label in labels_set:\n",
    "        for i in range(len(labels)):\n",
    "            if (labels[i] == label):\n",
    "                label_counts[label] += 1\n",
    "    \n",
    "    # Sort dictionary in order to make same bar plot every time\n",
    "    sorted_label_keys = sorted(label_counts.keys())\n",
    "    sorted_label_counts = {key: label_counts[key] for key in sorted_label_keys}\n",
    "    \n",
    "    # Create a bar plot\n",
    "    plt.figure(figsize=(10, 6)) \n",
    "    plt.bar(sorted_label_counts.keys(), sorted_label_counts.values(), color='skyblue')\n",
    "    plt.xlabel('Emotion')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Emotion Count')\n",
    "    plt.xticks(rotation=45) \n",
    "    \n",
    "    # Display the counts above each bar\n",
    "    for i, count in enumerate(sorted_label_counts.values()):\n",
    "        plt.text(i, count, str(count), ha='center', va='bottom')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85d2d210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which will delete random instances from images if they exceed the number upto\n",
    "\n",
    "def _decrease_bigger_indexes(target_images_indexes, random_index):\n",
    "    for i in range(len(target_images_indexes)):\n",
    "        if target_images_indexes[i] > random_index:\n",
    "            target_images_indexes[i] -= 1\n",
    "            \n",
    "    return target_images_indexes    \n",
    "    \n",
    "def random_delete_upto(images, labels, target_label, upto, seed = None):\n",
    "    \n",
    "    # Set seed\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "    target_images_indexes = []\n",
    "    data_images = images\n",
    "    data_labels = labels\n",
    "    \n",
    "    # Finding all target images\n",
    "    for i in range(len(images)):\n",
    "        if target_label == labels[i]:\n",
    "            target_images_indexes.append(i)\n",
    "            \n",
    "         \n",
    "    # Randomly deleting images and corresponsive labels\n",
    "    n = len(target_images_indexes)\n",
    "    while upto < n:\n",
    "        random_index = random.choice(target_images_indexes)\n",
    "        target_images_indexes.remove(random_index)\n",
    "        data_images = np.delete(data_images, random_index, axis=0)\n",
    "        data_labels = np.delete(data_labels, random_index, axis=0)\n",
    "        target_images_indexes = _decrease_bigger_indexes(target_images_indexes, random_index)\n",
    "        n -= 1\n",
    "\n",
    "    return data_images, data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35980789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting that puts my target label at the end\n",
    "\n",
    "def reverse_sort_key(item, target_label):\n",
    "    image, label = item\n",
    "    # If the label matches the target_label, return a large value to place it at the end\n",
    "    if label == target_label:\n",
    "        return 'zzzzzzzzzzzzzzzzz'\n",
    "    # Otherwise, return the original label for normal sorting\n",
    "    return label\n",
    "\n",
    "def random_delete_upto_2(images, labels, target_label, upto, seed=None):\n",
    "    \n",
    "    target_label_count = 0\n",
    "    for label in labels:\n",
    "        if target_label == label:\n",
    "            target_label_count += 1\n",
    "            \n",
    "    if target_label_count < upto:\n",
    "        return\n",
    "    \n",
    "    # Set seed\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    # Combine images and labels into a list of tuples\n",
    "    data = list(zip(images, labels))\n",
    "    \n",
    "    # Shuffle the combined data\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    # Sort data\n",
    "    sorted_data = sorted(data, key=lambda item: reverse_sort_key(item, target_label))    \n",
    "    \n",
    "    rest_labels_count = len(labels) - target_label_count\n",
    "    \n",
    "    # Delete from the end the excess of instances of target_class\n",
    "    data = sorted_data[:rest_labels_count + upto]\n",
    "    \n",
    "    # unzip data    \n",
    "    images, labels = zip(*data)\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66dfcba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function makes n_ensembles where each have n_counts instances. Reference is class from which will always \n",
    "# be taken the same n_counts of instances\n",
    "\n",
    "def make_ensembles(emotions, labels, n_ensembles, n_counts, reference = \"\"):\n",
    "    \n",
    "    n_classes = len(np.unique(labels))\n",
    "    data = zip(emotions, labels)\n",
    "    n_instances_of_class = n_counts * n_ensembles\n",
    "    \n",
    "\n",
    "    # removing n_counts of reference class, they will always be the same, and placing them in ref_data\n",
    "    sorted_data = sorted(data, key=lambda item: reverse_sort_key(item, reference)) \n",
    "    ref_data = sorted_data[-n_counts:]\n",
    "    sorted_data = sorted_data[:-n_counts]\n",
    "    ensembles = []\n",
    "    \n",
    "    ref_emotions, ref_labels = zip(*ref_data)\n",
    "    sorted_emotions, sorted_labels = zip(*sorted_data)\n",
    "\n",
    "    ref_emotions = list(ref_emotions)\n",
    "    ref_labels = list(ref_labels)\n",
    "    sorted_emotions = list(sorted_emotions)\n",
    "    sorted_labels = list(sorted_labels)\n",
    "\n",
    "    for i in range(n_ensembles):\n",
    "                \n",
    "        balanced_subset_data = []\n",
    "        balanced_subset_labels = []\n",
    "        \n",
    "        for emotion in ref_emotions:\n",
    "            balanced_subset_data.append(emotion)\n",
    "            \n",
    "        for label in ref_labels:\n",
    "            balanced_subset_labels.append(label)\n",
    "            \n",
    "        ensembles_data = []\n",
    "        \n",
    "        # Select n_instances from each majority class\n",
    "        for j in range(n_classes-1):  # -1 because we removed reference class\n",
    "            extracted_emotions = sorted_emotions[(j*n_instances_of_class)+i*n_counts:(j*n_instances_of_class)+(i+1)*n_counts]\n",
    "            extracted_labels = sorted_labels[(j*n_instances_of_class)+i*n_counts:(j*n_instances_of_class)+(i+1)*n_counts]\n",
    "            \n",
    "            for emotion in extracted_emotions:\n",
    "                balanced_subset_data.append(emotion)\n",
    "    \n",
    "            for label in extracted_labels:\n",
    "                balanced_subset_labels.append(label)\n",
    "        \n",
    "            \n",
    "        ensembles_data.append(np.array(balanced_subset_data))\n",
    "        ensembles_data.append(np.array(balanced_subset_labels))\n",
    "\n",
    "        ensembles.append(ensembles_data)\n",
    "    \n",
    "    return ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b994a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(train_data):\n",
    "#     # Initialize the StandardScaler\n",
    "#     scaler = StandardScaler()\n",
    "\n",
    "#     # Fit and transform LBP features\n",
    "#     scaler.fit(train_data)\n",
    "#     standardized_train_data = scaler.transform(train_data)\n",
    "    \n",
    "#     return standardized_train_data\n",
    "\n",
    "    train_array = np.array(train_data)\n",
    "\n",
    "    # Calculate the mean and standard deviation for each sublist (axis=0)\n",
    "    for i in range(len(train_array)):\n",
    "        if len(train_array[i]) != 555:\n",
    "            print(i)\n",
    "    means = np.mean(train_array, axis=0)\n",
    "    std_devs = np.std(train_array, axis=0)\n",
    "\n",
    "    # Perform standardization for each sublist\n",
    "    standardized_set = [(sublist - mean) / std_dev for sublist, mean, std_dev in zip(train_data, means, std_devs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b046264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(y_test, y_pred):\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(\"Confusion matrix: \\n\", conf_matrix,\n",
    "         \"\\nF1 score: \\n\", f1,\n",
    "         \"\\nAccuracy: \\n\", accuracy,\n",
    "         \"\\nClassification report: \\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a9b9a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for showing lbp_example\n",
    "\n",
    "from skimage.transform import rotate\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage import data\n",
    "from skimage.color import label2rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35bac703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_lbp(image, radius=1):\n",
    "\n",
    "#     points = 8 * radius\n",
    "\n",
    "#     # Compute LBP features\n",
    "#     lbp_image = feature.local_binary_pattern(image, P=points, R=radius, method=\"nri_uniform\")\n",
    "#     n_bins = int(lbp_image.max() + 1)\n",
    "#     lbp_histogram, _ = np.histogram(lbp_image.ravel(), bins=n_bins, range=(0, n_bins))\n",
    "\n",
    "#     # Normalize LBP histogram\n",
    "#     lbp_histogram = lbp_histogram.astype(\"float\")\n",
    "#     lbp_histogram /= (lbp_histogram.sum() + 1e-4)\n",
    "    \n",
    "#     return lbp_histogram\n",
    "\n",
    "def compute_lbp(image, radius=1, desired_length=None):\n",
    "\n",
    "    points = 8 * radius\n",
    "\n",
    "    # Compute LBP features\n",
    "    lbp_image = feature.local_binary_pattern(image, P=points, R=radius, method=\"nri_uniform\")\n",
    "    n_bins = int(lbp_image.max() + 1)\n",
    "    lbp_histogram, _ = np.histogram(lbp_image.ravel(), bins=n_bins, range=(0, n_bins))\n",
    "\n",
    "    # Normalize LBP histogram\n",
    "    lbp_histogram = lbp_histogram.astype(\"float\")\n",
    "    lbp_histogram /= (lbp_histogram.sum() + 1e-4)\n",
    "\n",
    "    # Ensure the histogram has the desired length\n",
    "    if desired_length != None:\n",
    "        if len(lbp_histogram) < desired_length:\n",
    "            # Pad the histogram with zeros\n",
    "            lbp_histogram = np.pad(lbp_histogram, (0, desired_length - len(lbp_histogram)))\n",
    "\n",
    "        elif len(lbp_histogram) > desired_length:\n",
    "            # Truncate the histogram\n",
    "            lbp_histogram = lbp_histogram[:desired_length]\n",
    "    \n",
    "    return lbp_histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3288d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lbp_hist(lbp_histogram):\n",
    "    \n",
    "    # Create a range for the x-axis (bin numbers)\n",
    "    bins = np.arange(len(lbp_histogram))\n",
    "\n",
    "    # Create a bar plot of the LBP histogram\n",
    "    plt.bar(bins, lbp_histogram, width=1, align='center')\n",
    "\n",
    "    plt.xlabel('LBP Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('LBP Histogram')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "beea363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _overlay_labels(image, lbp, labels):\n",
    "    mask = np.logical_or.reduce([lbp == each for each in labels])\n",
    "    return label2rgb(mask, image=image, bg_label=0, alpha=0.5)\n",
    "\n",
    "\n",
    "def _highlight_bars(bars, indexes):\n",
    "    for i in indexes:\n",
    "        bars[i].set_facecolor('r')\n",
    "\n",
    "\n",
    "\n",
    "def _hist(ax, lbp):\n",
    "    n_bins = int(lbp.max() + 1)\n",
    "    return ax.hist(lbp.ravel(), density=True, bins=n_bins, range=(0, n_bins),\n",
    "                   facecolor='0.5')\n",
    "\n",
    "\n",
    "# plot histograms of LBP of textures\n",
    "def plot_lbp_example(image, radius=1):\n",
    "    \n",
    "    points = 8 * radius\n",
    "    \n",
    "    lbp = local_binary_pattern(image, points, radius, method=\"uniform\")\n",
    "\n",
    "    fig, (ax_img, ax_hist) = plt.subplots(nrows=2, ncols=3, figsize=(9, 6))\n",
    "    plt.gray()\n",
    "\n",
    "    titles = ('edge', 'flat', 'corner')\n",
    "    w = width = radius - 1\n",
    "    edge_labels = range(points // 2 - w, points // 2 + w + 1)\n",
    "    flat_labels = list(range(0, w + 1)) + list(range(points - w, points + 2))\n",
    "    i_14 = points // 4            # 1/4th of the histogram\n",
    "    i_34 = 3 * (points // 4)      # 3/4th of the histogram\n",
    "    corner_labels = (list(range(i_14 - w, i_14 + w + 1)) +\n",
    "                     list(range(i_34 - w, i_34 + w + 1)))\n",
    "\n",
    "    label_sets = (edge_labels, flat_labels, corner_labels)\n",
    "\n",
    "    for ax, labels in zip(ax_img, label_sets):\n",
    "        ax.imshow(_overlay_labels(image, lbp, labels))\n",
    "\n",
    "    for ax, labels, name in zip(ax_hist, label_sets, titles):\n",
    "        counts, _, bars = _hist(ax, lbp)\n",
    "        _highlight_bars(bars, labels)\n",
    "        ax.set_ylim(top=np.max(counts[:-1]))\n",
    "        ax.set_xlim(right=points + 2)\n",
    "        ax.set_title(name)\n",
    "\n",
    "    ax_hist[0].set_ylabel('Percentage')\n",
    "    for ax in ax_img:\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccbb39ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, epochs):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Loss')\n",
    "    plt.plot(np.arange(0, epochs), history.history['loss'], label='train')\n",
    "    plt.plot(np.arange(0, epochs), history.history['val_loss'], label='validation')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title('Accuracy')\n",
    "    plt.plot(np.arange(0, epochs), history.history['accuracy'], label='train')\n",
    "    plt.plot(np.arange(0, epochs), history.history['val_accuracy'], label='validation')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
