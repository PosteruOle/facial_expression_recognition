{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b483a56d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, accuracy_score\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Step 1: Load Expression in-the-wild dataset\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Assuming the dataset is already available in a directory named 'dataset'\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Step 3: Training and Testing Split\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Split the dataset into training and testing sets\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mimages\u001b[49m, labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Step 4: Feature Extraction\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Implement feature extraction techniques such as LBP or HOG\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Extract features from X_train and X_test\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Step 5: Model Selection and Training\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Choose a machine learning model and train it on the extracted features\u001b[39;00m\n\u001b[1;32m     23\u001b[0m model \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m, C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Step 1: Load Expression in-the-wild dataset\n",
    "# Assuming the dataset is already available in a directory named 'dataset'\n",
    "\n",
    "# Step 2: Preprocessing\n",
    "# Implement preprocessing techniques such as face detection and alignment\n",
    "\n",
    "# Step 3: Training and Testing Split\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Feature Extraction\n",
    "# Implement feature extraction techniques such as LBP or HOG\n",
    "# Extract features from X_train and X_test\n",
    "\n",
    "# Step 5: Model Selection and Training\n",
    "# Choose a machine learning model and train it on the extracted features\n",
    "model = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Model Evaluation\n",
    "# Evaluate the trained model on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Step 7: Fine-tuning and Hyperparameter Optimization\n",
    "# Fine-tune the model by adjusting hyperparameters and evaluating the performance\n",
    "\n",
    "# Step 8: Model Deployment\n",
    "# Implement an interface or application for real-time facial expression recognition\n",
    "\n",
    "# Step 9: Documentation and Reporting\n",
    "# Document the project, methodology, and findings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef28922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1e1b08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5efe2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a73ce1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ef73928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "\n",
    "    data_dir_list = os.listdir(data_path)\n",
    "\n",
    "    img_data_list = []\n",
    "    img_label_list = []\n",
    "\n",
    "    # Traverse through each folder\n",
    "    for dataset in data_dir_list:\n",
    "        if os.path.isdir(data_path + '/' +  dataset):\n",
    "            img_list=os.listdir(data_path+'/'+ dataset)\n",
    "            \n",
    "            # Resize each image\n",
    "            for img in img_list:\n",
    "                input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "\n",
    "                # Convert image to grayscale\n",
    "                input_img_gray = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                input_img_resize=cv2.resize(input_img_gray,(48,48))\n",
    "                img_data_list.append(input_img_resize)\n",
    "                img_label_list.append(dataset)\n",
    "                \n",
    "    img_data = np.array(img_data_list)\n",
    "    img_labels = np.array(img_label_list)\n",
    "    \n",
    "    # Normalize the pixel values to the range [0, 1]\n",
    "    img_data = img_data.astype('float32') / 255.0\n",
    "\n",
    "    return img_data, img_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "883cb2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_data('datasets/ck+/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a90a9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fear\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Assuming 'image' is your 48x48 image with values between 0 and 1\n",
    "plt.imshow(images[1], cmap='gray') \n",
    "plt.axis('off')  \n",
    "plt.show()\n",
    "print(labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f1f37c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-11 19:19:56.976814: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-11 19:19:57.018552: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-11 19:19:57.020170: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-11 19:19:57.869880: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81346f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 48, 48, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1179776   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,199,495\n",
      "Trainable params: 1,199,495\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the images (resize, normalize, etc.)\n",
    "# You can use functions from libraries like OpenCV or TensorFlow for this.\n",
    "\n",
    "# Create a convolutional neural network (CNN) model\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(48, 48, 1)),  # Assuming grayscale images with a size of 48x48 pixels\n",
    "\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    layers.Dense(7, activation='softmax')  # 7 output classes for 7 emotions\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print a summary of the model architecture\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d98b0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce711a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb2c45d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5f6397",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
