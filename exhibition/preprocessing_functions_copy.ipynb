{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d9a58fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30d9e00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that traverse through given directory and for every directory returns \n",
    "# lists of image and the corresponding emotion\n",
    "\n",
    "def load_data(data_path):\n",
    "\n",
    "    data_dir_list = os.listdir(data_path)\n",
    "\n",
    "    img_data_list = []\n",
    "    img_label_list = []\n",
    "\n",
    "    # Traverse through each folder\n",
    "    for dataset in data_dir_list:\n",
    "        if os.path.isdir(data_path + '/' +  dataset):\n",
    "            img_list=os.listdir(data_path+'/'+ dataset)\n",
    "            \n",
    "            # Resize each image\n",
    "            for img in img_list:\n",
    "                input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "\n",
    "                # Convert image to grayscale\n",
    "                input_img_gray = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                input_img_resize=cv2.resize(input_img_gray,(48,48))\n",
    "                img_data_list.append(input_img_resize)\n",
    "                img_label_list.append(dataset)\n",
    "                \n",
    "    img_data = np.array(img_data_list)\n",
    "    img_labels = np.array(img_label_list)\n",
    "\n",
    "    return img_data, img_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f39f36b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(327, 48, 48)\n",
      "(327,)\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n"
     ]
    }
   ],
   "source": [
    "image_data, image_labels=load_data('./datasets/ck+/')\n",
    "print(image_data.shape)\n",
    "print(image_labels.shape)\n",
    "for i in range(50,60):\n",
    "    print(image_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac847d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values to the range [0, 1]\n",
    "\n",
    "def normalize_data(data):\n",
    "\n",
    "    return data.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebae99ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because faces should be symetrical, but they aren't perfectly symetric, one possible way to make more data is\n",
    "# to add mirrored images of faces. In this way, we are doubling instances of classes. We can exclude some classes\n",
    "# from being processed this way \n",
    "\n",
    "    \n",
    "def add_mirror_images(images, labels, exclude = []):\n",
    "    \n",
    "    all_images_list = []\n",
    "    all_labels_list = []\n",
    "    n = len(images)\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        all_images_list.append(images[i])\n",
    "        all_labels_list.append(labels[i])\n",
    "        \n",
    "        # Don't perform mirroring if label is set to excluded\n",
    "        if labels[i] not in exclude:\n",
    "            # Mirror the image horizontally\n",
    "            mirrored_image = cv2.flip(images[i], 1)\n",
    "            all_images_list.append(mirrored_image)\n",
    "            all_labels_list.append(labels[i]) \n",
    "        \n",
    "    all_images = np.array(all_images_list)\n",
    "    all_labels = np.array(all_labels_list)\n",
    "    \n",
    "    return all_images, all_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5960539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'image' is your 48x48 image with values between 0 and 1\n",
    "\n",
    "def plot_image(image, label):\n",
    "    plt.imshow(image, cmap='gray') \n",
    "    plt.axis('off')  \n",
    "    plt.show()\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3a97bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for making Bar plot which shows count of every emotion in alphabetical order\n",
    "\n",
    "def plot_count(images, labels):\n",
    "    \n",
    "    labels_set = set(labels)\n",
    "    label_counts = {}\n",
    "    \n",
    "    for label in labels_set:\n",
    "        label_counts[label] = 0\n",
    "    \n",
    "    for label in labels_set:\n",
    "        for i in range(len(images)):\n",
    "            if (labels[i] == label):\n",
    "                label_counts[label] += 1\n",
    "    \n",
    "    # Sort dictionary in order to make same bar plot every time\n",
    "    sorted_label_keys = sorted(label_counts.keys())\n",
    "    sorted_label_counts = {key: label_counts[key] for key in sorted_label_keys}\n",
    "    \n",
    "    # Create a bar plot\n",
    "    plt.figure(figsize=(10, 6)) \n",
    "    plt.bar(sorted_label_counts.keys(), sorted_label_counts.values(), color='skyblue')\n",
    "    plt.xlabel('Emotion')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Emotion Count')\n",
    "    plt.xticks(rotation=45) \n",
    "    \n",
    "    # Display the counts above each bar\n",
    "    for i, count in enumerate(sorted_label_counts.values()):\n",
    "        plt.text(i, count, str(count), ha='center', va='bottom')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85d2d210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which will delete random instances from images if they exceed the number upto\n",
    "\n",
    "def _decrease_bigger_indexes(target_images_indexes, random_index):\n",
    "    for i in range(len(target_images_indexes)):\n",
    "        if target_images_indexes[i] > random_index:\n",
    "            target_images_indexes[i] -= 1\n",
    "            \n",
    "    return target_images_indexes    \n",
    "    \n",
    "def random_delete_upto(images, labels, target_label, upto, seed = None):\n",
    "    \n",
    "    # Set seed\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "    target_images_indexes = []\n",
    "    data_images = images\n",
    "    data_labels = labels\n",
    "    \n",
    "    # Finding all target images\n",
    "    for i in range(len(images)):\n",
    "        if target_label == labels[i]:\n",
    "            target_images_indexes.append(i)\n",
    "            \n",
    "         \n",
    "    # Randomly deleting images and corresponsive labels\n",
    "    n = len(target_images_indexes)\n",
    "    while upto < n:\n",
    "        random_index = random.choice(target_images_indexes)\n",
    "        target_images_indexes.remove(random_index)\n",
    "        data_images = np.delete(data_images, random_index, axis=0)\n",
    "        data_labels = np.delete(data_labels, random_index, axis=0)\n",
    "        target_images_indexes = _decrease_bigger_indexes(target_images_indexes, random_index)\n",
    "        n -= 1\n",
    "\n",
    "    return data_images, data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b046264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(y_test, y_pred):\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(\"Confusion matrix: \\n\", conf_matrix,\n",
    "         \"\\nF1 score: \\n\", f1,\n",
    "         \"\\nAccuracy: \\n\", accuracy,\n",
    "         \"\\nClassification report: \\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a9b9a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for showing lbp_example\n",
    "\n",
    "from skimage.transform import rotate\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage import data\n",
    "from skimage.color import label2rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35bac703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lbp(image, radius=1):\n",
    "\n",
    "    points = 8 * radius\n",
    "\n",
    "    # Compute LBP features\n",
    "    lbp_image = feature.local_binary_pattern(image, P=points, R=radius, method=\"nri_uniform\")\n",
    "    n_bins = int(lbp_image.max() + 1)\n",
    "    lbp_histogram, _ = np.histogram(lbp_image.ravel(), bins=n_bins, range=(0, n_bins))\n",
    "\n",
    "    # Normalize LBP histogram\n",
    "    lbp_histogram = lbp_histogram.astype(\"float\")\n",
    "    lbp_histogram /= (lbp_histogram.sum() + 1e-6)\n",
    "    \n",
    "    return lbp_histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3288d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lbp_hist(lbp_histogram):\n",
    "    \n",
    "    # Create a range for the x-axis (bin numbers)\n",
    "    bins = np.arange(len(lbp_histogram))\n",
    "\n",
    "    # Create a bar plot of the LBP histogram\n",
    "    plt.bar(bins, lbp_histogram, width=1, align='center')\n",
    "\n",
    "    plt.xlabel('LBP Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('LBP Histogram')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "beea363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _overlay_labels(image, lbp, labels):\n",
    "    mask = np.logical_or.reduce([lbp == each for each in labels])\n",
    "    return label2rgb(mask, image=image, bg_label=0, alpha=0.5)\n",
    "\n",
    "\n",
    "def _highlight_bars(bars, indexes):\n",
    "    for i in indexes:\n",
    "        bars[i].set_facecolor('r')\n",
    "\n",
    "\n",
    "\n",
    "def _hist(ax, lbp):\n",
    "    n_bins = int(lbp.max() + 1)\n",
    "    return ax.hist(lbp.ravel(), density=True, bins=n_bins, range=(0, n_bins),\n",
    "                   facecolor='0.5')\n",
    "\n",
    "\n",
    "# plot histograms of LBP of textures\n",
    "def plot_lbp_example(image, radius=1):\n",
    "    \n",
    "    points = 8 * radius\n",
    "    \n",
    "    lbp = local_binary_pattern(image, points, radius, method=\"uniform\")\n",
    "\n",
    "    fig, (ax_img, ax_hist) = plt.subplots(nrows=2, ncols=3, figsize=(9, 6))\n",
    "    plt.gray()\n",
    "\n",
    "    titles = ('edge', 'flat', 'corner')\n",
    "    w = width = radius - 1\n",
    "    edge_labels = range(points // 2 - w, points // 2 + w + 1)\n",
    "    flat_labels = list(range(0, w + 1)) + list(range(points - w, points + 2))\n",
    "    i_14 = points // 4            # 1/4th of the histogram\n",
    "    i_34 = 3 * (points // 4)      # 3/4th of the histogram\n",
    "    corner_labels = (list(range(i_14 - w, i_14 + w + 1)) +\n",
    "                     list(range(i_34 - w, i_34 + w + 1)))\n",
    "\n",
    "    label_sets = (edge_labels, flat_labels, corner_labels)\n",
    "\n",
    "    for ax, labels in zip(ax_img, label_sets):\n",
    "        ax.imshow(_overlay_labels(image, lbp, labels))\n",
    "\n",
    "    for ax, labels, name in zip(ax_hist, label_sets, titles):\n",
    "        counts, _, bars = _hist(ax, lbp)\n",
    "        _highlight_bars(bars, labels)\n",
    "        ax.set_ylim(top=np.max(counts[:-1]))\n",
    "        ax.set_xlim(right=points + 2)\n",
    "        ax.set_title(name)\n",
    "\n",
    "    ax_hist[0].set_ylabel('Percentage')\n",
    "    for ax in ax_img:\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "007280e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROWS = 48\n",
    "COLS = 48\n",
    "NUM_OF_CHANNELS = 3\n",
    "NUM_OF_CLASSES = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "873c861e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 12:25:00.696791: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-14 12:25:00.721727: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-14 12:25:00.878165: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-14 12:25:00.878949: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-14 12:25:01.535236: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dense, Dropout, Flatten, BatchNormalization\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2403c8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Da bismo dobili sve jedinstvene vrednosti liste y_stratify koristimo klasu Counter iz paketa\n",
    "# collections\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "799b6840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 12:25:05.720070: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-14 12:25:05.722218: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "print('Hi there!')\n",
    "\n",
    "#Alexnet arhitektura\n",
    "\n",
    "alexnet_model = Sequential([\n",
    "    Conv2D(96, kernel_size=(11,11), strides=(1,1), padding='same', activation='relu', input_shape=(ROWS, COLS, 1)),\n",
    "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    Conv2D(256, kernel_size=(5,5), strides=(1,1), padding='same', activation='relu'),\n",
    "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    Conv2D(384, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'),\n",
    "    Conv2D(384, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'),\n",
    "    Conv2D(256, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'),\n",
    "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(2304, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2304, activation='relu'),\n",
    "    Dense(NUM_OF_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f8f0b350",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alexnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a7cb6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a0b600b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faf91d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5660081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treniramo model\n",
    "#history = alexnet_model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "207cdd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(327, 48, 48)\n",
      "(327,)\n",
      "(327, 48, 48)\n",
      "(654, 48, 48)\n",
      "(654,)\n",
      "contempt\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contempt\n",
      "------------------------------------------------\n",
      "New stage!\n"
     ]
    }
   ],
   "source": [
    "image_data, image_labels=load_data('./datasets/ck+/')\n",
    "print(image_data.shape)\n",
    "print(image_labels.shape)\n",
    "#for i in range(50,60):\n",
    "#    print(image_labels[i])\n",
    "image_data=normalize_data(image_data)\n",
    "print(image_data.shape)\n",
    "all_images, all_labels=add_mirror_images(image_data, image_labels)\n",
    "print(all_images.shape)\n",
    "print(all_labels.shape)\n",
    "print(all_labels[0])\n",
    "plot_image(all_images[0], all_labels[0])\n",
    "print('------------------------------------------------')\n",
    "print('New stage!')\n",
    "#plot_count(all_images, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed17ea6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into train, test and validation sets...\n"
     ]
    }
   ],
   "source": [
    "print(\"Splitting data into train, test and validation sets...\")\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "            all_images, all_labels, test_size=0.15, random_state=7)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train_val, y_train_val, test_size=0.15, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e70c8308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(471, 48, 48)\n",
      "(99, 48, 48)\n",
      "(471,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "X_train[0].ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e8dcd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/keras/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/keras/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/keras/losses.py\", line 1984, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/keras/backend.py\", line 5559, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 7) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Treniramo model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m alexnet_model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39mAdam(\u001b[38;5;241m0.001\u001b[39m), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43malexnet_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileqhi67x_x.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/keras/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/keras/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/keras/losses.py\", line 1984, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/keras/backend.py\", line 5559, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 7) are incompatible\n"
     ]
    }
   ],
   "source": [
    "#Treniramo model\n",
    "alexnet_model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "history = alexnet_model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8835d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4cddb156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(471,)\n",
      "<built-in method astype of numpy.ndarray object at 0x7fe0c40d9750>\n",
      "happy\n",
      "(471,)\n",
      "happy\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "number_of_classes=7\n",
    "\n",
    "#y_train = utils.to_categorical(y_train, number_of_classes)\n",
    "#y_test = utils.to_categorical(y_test, number_of_classes)\n",
    "print(y_train.shape)\n",
    "print(y_train.astype)\n",
    "print(y_train[0])\n",
    "#y_train_help=np.array((471, 7))\n",
    "y_train_help=[]\n",
    "for image in y_train:\n",
    "    if image=='anger':\n",
    "        #print('Hi there!')\n",
    "        y_train_help=[1,0,0,0,0,0,0]\n",
    "    if image=='contempt':\n",
    "        y_train_help=[0,1,0,0,0,0,0]\n",
    "    if image=='disgust':\n",
    "        y_train_help=[0,0,1,0,0,0,0]\n",
    "    if image=='fear':\n",
    "        y_train_help=[0,0,0,1,0,0,0]\n",
    "    if image=='happy':\n",
    "        y_train_help=[0,0,0,0,1,0,0]\n",
    "    if image=='sadness':\n",
    "        y_train_help=[0,0,0,0,0,1,0]\n",
    "    if image=='surprise':\n",
    "        y_train_help=[0,0,0,0,0,0,1]\n",
    "    image=y_train_help       \n",
    "        \n",
    "print(y_train.shape)\n",
    "print(y_train[0])\n",
    "#np."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "786580c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(48,48,1)\n",
    "model = Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    Conv2D(filters=1, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(number_of_classes, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7fab22d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_15 (Conv2D)          (None, 48, 48, 1)         10        \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 48, 48, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 24, 24, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 36864)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               4718720   \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,720,273\n",
      "Trainable params: 4,720,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5b5bf972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import model_to_dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "58e0cce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"242pt\" height=\"568pt\" viewBox=\"0.00 0.00 268.00 629.00\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1.11 1.11) rotate(0) translate(4 625)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-625 264,-625 264,4 -4,4\"/>\n",
       "<!-- 140599944595392 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140599944595392</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"47.5,-584.5 47.5,-620.5 212.5,-620.5 212.5,-584.5 47.5,-584.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"82.5\" y=\"-598.8\" font-family=\"Times,serif\" font-size=\"14.00\">input_7</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"117.5,-584.5 117.5,-620.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"165\" y=\"-598.8\" font-family=\"Times,serif\" font-size=\"14.00\">InputLayer</text>\n",
       "</g>\n",
       "<!-- 140599944596448 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140599944596448</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"47.5,-511.5 47.5,-547.5 212.5,-547.5 212.5,-511.5 47.5,-511.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"93.5\" y=\"-525.8\" font-family=\"Times,serif\" font-size=\"14.00\">conv2d_15</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"139.5,-511.5 139.5,-547.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"176\" y=\"-525.8\" font-family=\"Times,serif\" font-size=\"14.00\">Conv2D</text>\n",
       "</g>\n",
       "<!-- 140599944595392&#45;&gt;140599944596448 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140599944595392-&gt;140599944596448</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M130,-584.31C130,-576.29 130,-566.55 130,-557.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"133.5,-557.53 130,-547.53 126.5,-557.53 133.5,-557.53\"/>\n",
       "</g>\n",
       "<!-- 140599944597456 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140599944597456</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"47.5,-438.5 47.5,-474.5 212.5,-474.5 212.5,-438.5 47.5,-438.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"93.5\" y=\"-452.8\" font-family=\"Times,serif\" font-size=\"14.00\">conv2d_16</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"139.5,-438.5 139.5,-474.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"176\" y=\"-452.8\" font-family=\"Times,serif\" font-size=\"14.00\">Conv2D</text>\n",
       "</g>\n",
       "<!-- 140599944596448&#45;&gt;140599944597456 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140599944596448-&gt;140599944597456</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M130,-511.31C130,-503.29 130,-493.55 130,-484.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"133.5,-484.53 130,-474.53 126.5,-484.53 133.5,-484.53\"/>\n",
       "</g>\n",
       "<!-- 140599944596688 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140599944596688</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-365.5 0,-401.5 260,-401.5 260,-365.5 0,-365.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"70\" y=\"-379.8\" font-family=\"Times,serif\" font-size=\"14.00\">max_pooling2d_8</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"140,-365.5 140,-401.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"200\" y=\"-379.8\" font-family=\"Times,serif\" font-size=\"14.00\">MaxPooling2D</text>\n",
       "</g>\n",
       "<!-- 140599944597456&#45;&gt;140599944596688 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140599944597456-&gt;140599944596688</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M130,-438.31C130,-430.29 130,-420.55 130,-411.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"133.5,-411.53 130,-401.53 126.5,-411.53 133.5,-411.53\"/>\n",
       "</g>\n",
       "<!-- 140599944684352 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140599944684352</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"43.5,-292.5 43.5,-328.5 216.5,-328.5 216.5,-292.5 43.5,-292.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"92.5\" y=\"-306.8\" font-family=\"Times,serif\" font-size=\"14.00\">dropout_12</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"141.5,-292.5 141.5,-328.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"179\" y=\"-306.8\" font-family=\"Times,serif\" font-size=\"14.00\">Dropout</text>\n",
       "</g>\n",
       "<!-- 140599944596688&#45;&gt;140599944684352 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140599944596688-&gt;140599944684352</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M130,-365.31C130,-357.29 130,-347.55 130,-338.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"133.5,-338.53 130,-328.53 126.5,-338.53 133.5,-338.53\"/>\n",
       "</g>\n",
       "<!-- 140599944686656 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>140599944686656</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"56.5,-219.5 56.5,-255.5 203.5,-255.5 203.5,-219.5 56.5,-219.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"96\" y=\"-233.8\" font-family=\"Times,serif\" font-size=\"14.00\">flatten_6</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"135.5,-219.5 135.5,-255.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"169.5\" y=\"-233.8\" font-family=\"Times,serif\" font-size=\"14.00\">Flatten</text>\n",
       "</g>\n",
       "<!-- 140599944684352&#45;&gt;140599944686656 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140599944684352-&gt;140599944686656</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M130,-292.31C130,-284.29 130,-274.55 130,-265.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"133.5,-265.53 130,-255.53 126.5,-265.53 133.5,-265.53\"/>\n",
       "</g>\n",
       "<!-- 140599944687424 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>140599944687424</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"58,-146.5 58,-182.5 202,-182.5 202,-146.5 58,-146.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"99.5\" y=\"-160.8\" font-family=\"Times,serif\" font-size=\"14.00\">dense_12</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"141,-146.5 141,-182.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"171.5\" y=\"-160.8\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n",
       "</g>\n",
       "<!-- 140599944686656&#45;&gt;140599944687424 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>140599944686656-&gt;140599944687424</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M130,-219.31C130,-211.29 130,-201.55 130,-192.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"133.5,-192.53 130,-182.53 126.5,-192.53 133.5,-192.53\"/>\n",
       "</g>\n",
       "<!-- 140599944728736 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>140599944728736</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"43.5,-73.5 43.5,-109.5 216.5,-109.5 216.5,-73.5 43.5,-73.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"92.5\" y=\"-87.8\" font-family=\"Times,serif\" font-size=\"14.00\">dropout_13</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"141.5,-73.5 141.5,-109.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"179\" y=\"-87.8\" font-family=\"Times,serif\" font-size=\"14.00\">Dropout</text>\n",
       "</g>\n",
       "<!-- 140599944687424&#45;&gt;140599944728736 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>140599944687424-&gt;140599944728736</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M130,-146.31C130,-138.29 130,-128.55 130,-119.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"133.5,-119.53 130,-109.53 126.5,-119.53 133.5,-119.53\"/>\n",
       "</g>\n",
       "<!-- 140599944729888 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>140599944729888</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"58,-0.5 58,-36.5 202,-36.5 202,-0.5 58,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"99.5\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">dense_13</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"141,-0.5 141,-36.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"171.5\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n",
       "</g>\n",
       "<!-- 140599944728736&#45;&gt;140599944729888 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>140599944728736-&gt;140599944729888</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M130,-73.31C130,-65.29 130,-55.55 130,-46.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"133.5,-46.53 130,-36.53 126.5,-46.53 133.5,-46.53\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(SVG(model_to_dot(model, dpi=65).create(prog='dot', format='svg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6a4174bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=accuracy_score,optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e0be20c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3eb73834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(471, 48, 48)\n",
      "(471,)\n",
      "[[0.3372549  0.3372549  0.3254902  ... 0.0627451  0.07843138 0.26666668]\n",
      " [0.33333334 0.3372549  0.2784314  ... 0.07843138 0.03921569 0.15294118]\n",
      " [0.3372549  0.34117648 0.22352941 ... 0.09411765 0.06666667 0.08235294]\n",
      " ...\n",
      " [0.2509804  0.25490198 0.25882354 ... 0.14509805 0.18039216 0.2509804 ]\n",
      " [0.24705882 0.24705882 0.2509804  ... 0.13725491 0.18431373 0.24313726]\n",
      " [0.24313726 0.24705882 0.25490198 ... 0.14117648 0.2        0.2627451 ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bb71c161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 169, in wrapper  *\n        return func(*args, **kwargs)\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 221, in accuracy_score  *\n        y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 86, in _check_targets  *\n        check_consistent_length(y_true, y_pred)\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 395, in check_consistent_length  *\n        uniques = np.unique(lengths)\n    File \"<__array_function__ internals>\", line 180, in unique  **\n        \n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/numpy/lib/arraysetops.py\", line 272, in unique\n        ar = np.asanyarray(ar)\n\n    NotImplementedError: Cannot convert a symbolic tf.Tensor (accuracy_score/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileqhi67x_x.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filequq115g1.py:23\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(func), \u001b[38;5;28mtuple\u001b[39m(ag__\u001b[38;5;241m.\u001b[39mld(args)), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(kwargs)), fscope)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file_cmlwvy4.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__accuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m      9\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     10\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 11\u001b[0m (y_type, y_true, y_pred) \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(_check_targets), (ag__\u001b[38;5;241m.\u001b[39mld(y_true), ag__\u001b[38;5;241m.\u001b[39mld(y_pred)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(check_consistent_length), (ag__\u001b[38;5;241m.\u001b[39mld(y_true), ag__\u001b[38;5;241m.\u001b[39mld(y_pred), ag__\u001b[38;5;241m.\u001b[39mld(sample_weight)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state\u001b[39m():\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filepu9dgv12.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf___check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      9\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     10\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 11\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(check_consistent_length), (ag__\u001b[38;5;241m.\u001b[39mld(y_true), ag__\u001b[38;5;241m.\u001b[39mld(y_pred)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m type_true \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(type_of_target), (ag__\u001b[38;5;241m.\u001b[39mld(y_true),), \u001b[38;5;28mdict\u001b[39m(input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m'\u001b[39m), fscope)\n\u001b[1;32m     13\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(type_of_target), (ag__\u001b[38;5;241m.\u001b[39mld(y_pred),), \u001b[38;5;28mdict\u001b[39m(input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m'\u001b[39m), fscope)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filejonw51n0.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__check_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mFunctionScope(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheck_consistent_length\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfscope\u001b[39m\u001b[38;5;124m'\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mSTD) \u001b[38;5;28;01mas\u001b[39;00m fscope:\n\u001b[1;32m      9\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m [ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(_num_samples), (ag__\u001b[38;5;241m.\u001b[39mld(X),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(arrays) \u001b[38;5;28;01mif\u001b[39;00m (ag__\u001b[38;5;241m.\u001b[39mld(X) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)]\n\u001b[0;32m---> 10\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(np)\u001b[38;5;241m.\u001b[39munique, (ag__\u001b[38;5;241m.\u001b[39mld(lengths),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state\u001b[39m():\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ()\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/arraysetops.py:272\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_unique_dispatcher)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique\u001b[39m(ar, return_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    140\u001b[0m            return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, equal_nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    141\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m    Find the unique elements of an array.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    270\u001b[0m \n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 272\u001b[0m     ar \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m         ret \u001b[38;5;241m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[1;32m    275\u001b[0m                         equal_nan\u001b[38;5;241m=\u001b[39mequal_nan)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: in user code:\n\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 169, in wrapper  *\n        return func(*args, **kwargs)\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 221, in accuracy_score  *\n        y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 86, in _check_targets  *\n        check_consistent_length(y_true, y_pred)\n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 395, in check_consistent_length  *\n        uniques = np.unique(lengths)\n    File \"<__array_function__ internals>\", line 180, in unique  **\n        \n    File \"/home/ptesic@syrmia.com/.local/lib/python3.8/site-packages/numpy/lib/arraysetops.py\", line 272, in unique\n        ar = np.asanyarray(ar)\n\n    NotImplementedError: Cannot convert a symbolic tf.Tensor (accuracy_score/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
